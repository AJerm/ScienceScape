PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	EY	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J	Cvetkovic, S; Stojanovic, MB; Nikolic, SV				Cvetkovic, Stevica; Stojanovic, Milos B.; Nikolic, Sasa V.			Hierarchical ELM ensembles for visual descriptor fusion	INFORMATION FUSION			English	Article						Feature fusion; Extreme Learning Machine; Hierarchical classifiers; Scene classification	EXTREME LEARNING MACHINES; TEXTURE CLASSIFICATION; IMAGE CLASSIFICATION; COLOR; REGRESSION; RETRIEVAL; FEATURES; NETWORK; SCALE; SCENE	Extreme Learning Machines (ELM) have been successfully applied to variety of classification problems by utilizing a single descriptor type. However, a single descriptor may be insufficient for the visual classification task, due to the high level of intra-class variability coupled with low inter-class distance. Although several studies have investigated methods for combining multiple descriptors by ELM, they predominantly apply a simple concatenation of descriptors before classifying them. This type of descriptor fusion may impose problems of descriptor compatibility, high dimensionality and restricted accuracy. In this paper, we propose a hierarchical descriptors fusion strategy at the decision level ("late-fusion"), which relies on ELM ensembles (ELM-E). The proposed method, denoted as H-ELM-E, effectively combines multiple complementary descriptors by a two-level ELM-E based architecture, which ensures that a more informative descriptors will gain more impact on the final decision. In the first level, a separate ELM-E classifier is trained for every image descriptor. In the second level, the output scores from the previous level are aggregated into the mid-level representation which is conducted to an additional ELM-E classifier. The exhaustive experimental evaluation confirmed that the proposed hierarchical ELM-E based strategy is superior to the single-descriptor methods as well as "early fusion" of multiple descriptors, for the visual classification task. Additionally, it was shown that significant accuracy improvement is achieved by integrating ensembles of ELM as a basic classifier, instead of using a single ELM. (C) 2017 Elsevier B.V. All rights reserved.	[Cvetkovic, Stevica; Nikolic, Sasa V.] Univ Nis, Fac Elect Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia; [Stojanovic, Milos B.] Coll Appl Tech Sci Nis, Aleksandra Medvedeva 20, Nish 18000, Serbia	Cvetkovic, S (reprint author), Univ Nis, Fac Elect Engn, Aleksandra Medvedeva 14, Nish 18000, Serbia.	stevica.cvetkovic@elfak.ni.ac.rs					Akusok A, 2015, IEEE ACCESS, V3, P1011, DOI 10.1109/ACCESS.2015.2450498; Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0; Ayerdi B, 2014, NEURAL NETWORKS, V52, P33, DOI 10.1016/j.neunet.2014.01.003; Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown G., 2005, Information Fusion, V6, P5, DOI 10.1016/j.inffus.2004.04.004; Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637; Cao JW, 2016, MULTIMED TOOLS APPL, V75, P2839, DOI 10.1007/s11042-014-2424-1; Cao JW, 2014, C IND ELECT APPL, P1163, DOI 10.1109/ICIEA.2014.6931341; Cao JW, 2014, BIOMED RES INT, DOI 10.1155/2014/103054; Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0; Cvetkovic S, 2015, SIGNAL PROCESS-IMAGE, V39, P111, DOI 10.1016/j.image.2015.09.004; Du PJ, 2014, INT J REMOTE SENS, V35, P7978, DOI 10.1080/2150704X.2014.978952; Eidenberger H, 2004, MULTIMEDIA SYST, V10, P84, DOI 10.1007/s00530-004-0141-8; Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003; Granitto PM, 2005, ARTIF INTELL, V163, P139, DOI 10.1016/j.artint.2004.09.006; Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2015, COGN COMPUT, V7, P263, DOI 10.1007/s12559-015-9333-0; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Kaya Y, 2014, J EXP THEOR ARTIF IN, V26, P267, DOI 10.1080/0952813X.2013.861875; Khan FS, 2015, PATTERN RECOGN LETT, V51, P16, DOI 10.1016/j.patrec.2014.07.020; KHAN FS, 2013, COMP ANAL IM PATT, V8047, P154; Krizhevsky A., ADV NEURAL INFORM PR, V25, P1097; Lan Y, 2009, NEUROCOMPUTING, V72, P3391, DOI 10.1016/j.neucom.2009.02.013; LAZEBNIK S, 2006, P IEEE INT C COMP VI, V2006, P2169, DOI DOI 10.1109/CVPR.2006.68; Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526; Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602; Liu N, 2010, IEEE SIGNAL PROC LET, V17, P754, DOI 10.1109/LSP.2010.2053356; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ren JF, 2015, PATTERN RECOGN, V48, P3180, DOI 10.1016/j.patcog.2015.02.001; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Salembier P., INTRO MPEG 7 MULTIME; Samat A, 2014, IEEE J-STARS, V7, P1060, DOI 10.1109/JSTARS.2014.2301775; Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399; Tian XL, 2014, SIGNAL PROCESS-IMAGE, V29, P530, DOI 10.1016/j.image.2014.01.010; ul Hussain S, 2012, LECT NOTES COMPUT SC, V7573, P716, DOI 10.1007/978-3-642-33709-3_51; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; van Heeswijk M, 2011, NEUROCOMPUTING, V74, P2430, DOI 10.1016/j.neucom.2010.11.034; Wang XL, 2014, NEUROCOMPUTING, V128, P31, DOI 10.1016/j.neucom.2013.02.053; Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Yang Y, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1465, DOI 10.1109/ICCV.2011.6126403; Zhang L, 2012, IEEE IMAGE PROC, P81, DOI 10.1109/ICIP.2012.6466800; Zhao Y., ADV INTELLIGENT COMP, P112	51	0	0	26	26	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	MAY	2018	41						16	24		10.1016/j.inffus.2017.07.003				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	FP5LX	WOS:000417662100003					2018-01-30	
J	Zhang, SB; Stogin, W; Alshurafa, N				Zhang, Shibo; Stogin, William; Alshurafa, Nabil			I sense overeating: Motif-based machine learning framework to detect overeating using wrist-worn sensing	INFORMATION FUSION			English	Article						Wrist-worn sensors; Wearables; Hand-to-mouth gestures; Overeating; Inertial sensors; Motif-based segmentation; K-Spectral Centroid Clustering; Fusion; Classification; Feeding gesture		Obesity, caused primarily by overeating, is a preventable chronic disease yielding staggering healthcare costs. To detect overeating passively, a machine learning framework was designed to detect and accurately count the number of feeding gestures during an eating episode to characterize each eating episode with a feeding gesture count using a 6-axis inertial wrist-worn sensor. Moreover, detecting feeding gestures is useful to aid in end-of-day dietary recalls. It has been shown that feeding gesture count correlates with caloric intake; the more one eats, the more calories one is likely consuming. Recent research has shown promise in passively detecting feeding gestures, but this effort focuses on bridging detection of feeding gesture count and identifying overeating episodes. This paper presents results on three experiments: highly structured (participants pretending to eat), in-lab structured with confounding activities (participants eating while performing other scripted activities), and unstructured overeating (participants induced to overeat while watching television and eating their favorite foods). Our experiment successfully induced overeating in 50% of the participants, showing a correlation between feeding gesture count and caloric intake in unstructured eating (r=.79, p-value=.007). Results provide an approximate upper bound on feeding gesture classification using exact segmentation techniques, and show improvement when compared to prior sliding window techniques. Results also suggest the importance of stressing the challenge of accurate segmentation over identifying the accurate classification technique in detection of feeding gestures. Since participant-dependent models provide optimal results, a motif-based time-point fusion classification (MTFC) framework is proposed using spectral energy density, K-Spectral Centroid Clustering, symbolic aggregate approximation (SAX), a Random Forest classifier (trained on segmented motifs) and a time-point classifier fusion technique to show reliable classification of feeding gestures (75% F-measure), and a 94% accuracy of feeding gesture count in the unstructured eating experiment, resulting in a root mean square error of 2.9 feeding gestures. Mapping feeding gesture count to caloric intake, we obtain a rough estimate of whether participants overate while watching television. (C) 2017 Elsevier B.V. All rights reserved.	[Zhang, Shibo; Stogin, William; Alshurafa, Nabil] Northwestern Univ, EECS, Evanston, IL 60208 USA; [Alshurafa, Nabil] Northwestern Univ, Prevent Med Dept, Evanston, IL 60208 USA	Zhang, SB (reprint author), Northwestern Univ, EECS, Evanston, IL 60208 USA.	shibozhang2015@u.northwestern.edu					Alshurafa N., 2013, BSN, P1; Amft O, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P160, DOI 10.1109/ISWC.2005.17; Amft O, 2009, IEEE PERVAS COMPUT, V8, P62, DOI 10.1109/MPRV.2009.32; Andreoli A., SPINE HRV BSN BASED, P369; Bongers P, 2013, APPETITE, V67, P74, DOI 10.1016/j.appet.2013.03.017; COOLS J, 1992, J ABNORM PSYCHOL, V101, P348, DOI 10.1037/0021-843X.101.2.348; Dong YJ, 2014, IEEE J BIOMED HEALTH, V18, P1253, DOI 10.1109/JBHI.2013.2282471; Dong YJ, 2012, APPL PSYCHOPHYS BIOF, V37, P205, DOI 10.1007/s10484-012-9194-1; Everingham M., 2007, TECHNICAL REPORT; Fortino G, 2013, IEEE T HUM-MACH SYST, V43, P115, DOI 10.1109/TSMCC.2012.2215852; Fouse A., 2011, CHI 11 HUM FACT COMP, P299, DOI [10.1145/1979742.1979706, DOI 10.1145/1979742.1979706]; Goldschmidt AB, 2008, INT J EAT DISORDER, V41, P153, DOI 10.1002/eat.20481; Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005; GREENO CG, 1994, PSYCHOL BULL, V115, P444, DOI 10.1037//0033-2909.115.3.444; Herman CP, 2008, PHYSIOL BEHAV, V94, P722, DOI 10.1016/j.physbeh.2008.04.014; Junker H., 2010, PATTERN RECOGN, V41, P2010; Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Maramis C, 2016, 9TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2016), DOI 10.1145/2903220.2903239; Oppenheim A. V., 1996, SIGNALS SYSTEMS; Parate A, 2014, MOBISYS'14: PROCEEDINGS OF THE 12TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P149, DOI 10.1145/2594368.2594379; Pedley M., 2012, FREESCALE SEMICONDUC; Rahman T, 2016, DH'16: PROCEEDINGS OF THE 2016 DIGITAL HEALTH CONFERENCE, P141, DOI 10.1145/2896338.2896359; ROZA AM, 1984, AM J CLIN NUTR, V40, P168; Saleheen N, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P999, DOI 10.1145/2750858.2806897; Sazonov E, 2013, J STUD ALCOHOL DRUGS, V74, P956, DOI 10.15288/jsad.2013.74.956; Sen S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P585, DOI 10.1109/PERCOMW.2015.7134103; Thomaz E, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1029, DOI 10.1145/2750858.2807545; Yang J., ACM INT C WEB SEARCH; Zhang S., 2016, OB SOC ANN M OBESITY; Zhang S., 2016, INT C BOD AR NETW BO	31	0	0	38	38	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	MAY	2018	41						37	47		10.1016/j.inffus.2017.08.003				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	FP5LX	WOS:000417662100005					2018-01-30	
J	Cao, JJ; Li, WF; Ma, CC; Tao, ZW				Cao, Jingjing; Li, Wenfeng; Ma, Congcong; Tao, Zhiwen			Optimizing multi-sensor deployment via ensemble pruning for wearable activity recognition	INFORMATION FUSION			English	Article						Multi-sensor data fusion; Human activity recognition; Ensemble pruning; Body sensor networks	EXTREME LEARNING-MACHINE; BODY SENSOR NETWORKS; ORDERED AGGREGATION; FUSION; MODELS; PERFORMANCE; FRAMEWORK; SYSTEM	With the rapid development of sensor types and processers, most wearable activity recognition systems tend to making use of multiple homogeneous or heterogeneous sensors to obtain plethora information. However, in a realistic environment, it is difficult to configure an appropriate multi-sensor deployment to gain a tradeoff among computational complexity, accuracy and subject personality. In this paper, a multi-sensor fusion with ensemble pruning system (MSF-EP) is designed to connect with multi-sensor based wearable activity recognition system. As a result, the multi-sensor configuration problem is transformed to multiple ensemble classifier pruning problem. With respect to ensemble pruning for MSF-EP system, two popular order-based ensemble pruning approaches are utilized firstly: reduce-error pruning (RE) and complementarily pruning (Comp). Then, in light of the proposed MSF-EP system, two new ensemble pruning criteria are proposed: mRMR pruning and discriminative pruning (Disc). The mRMR pruning measure is based on mutual information and is a composite criterion of classifier redundancy and relevance with regard to the selected classifier set. Taking into account the discriminations of misclassified instances and correctly classified instances in classifier subset selected respectively, another ensemble pruning measure Disc, which combining RE pruning and Comp pruning, is presented in the form of mutual information also. Finally, the proposed pruning learner with lower error is selected as final ensemble classifier. Through the algorithm, the number and type of multi-sensor are appropriately decided to optimize the multi-sensor fusion without regrading the accuracy performance. The system conducts experimental studies on two real-world activity recognition data sets and the results show the superiority of system over other ensemble algorithms. (C) 2017 Elsevier B.V. All rights reserved.	[Cao, Jingjing; Li, Wenfeng; Ma, Congcong; Tao, Zhiwen] Wuhan Univ Technol, Sch Logist Engn, Wuhan 430063, Hubei, Peoples R China	Li, WF (reprint author), Wuhan Univ Technol, Sch Logist Engn, Wuhan 430063, Hubei, Peoples R China.	liwf@whut.edu.cn		MA, CONGCONG/0000-0002-1579-2229	National Natural Science Foundation of China [61502360, 61571336]	The work described in this paper was partially supported by National Natural Science Foundation of China under the Grant No. 61502360 and No. 61571336.	Abdallah ZS, 2015, NEUROCOMPUTING, V150, P304, DOI 10.1016/j.neucom.2014.09.074; Abouelenien M., 2012, COMP COMM NETW TECHN, P1; Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019; Avci U, 2014, IEEE T KNOWL DATA EN, V26, P889, DOI 10.1109/TKDE.2013.127; Barbierato E, 2014, FUTURE GENER COMP SY, V37, P345, DOI 10.1016/j.future.2013.12.036; Barshan B, 2014, COMPUT J, V57, P1649, DOI 10.1093/comjnl/bxt075; Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014; Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520; Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883; Chernbumroong S, 2014, DECIS SUPPORT SYST, V66, P61, DOI 10.1016/j.dss.2014.06.005; Dai Q, 2015, APPL SOFT COMPUT, V28, P237, DOI 10.1016/j.asoc.2014.10.045; Fortino G, 2015, INFORM FUSION, V22, P50, DOI 10.1016/j.inffus.2014.03.005; Fortino G, 2013, IEEE T HUM-MACH SYST, V43, P115, DOI 10.1109/TSMCC.2012.2215852; Galar M, 2016, INFORM SCIENCES, V354, P178, DOI 10.1016/j.ins.2016.02.056; Ghasemzadeh H, 2014, IEEE T HUM-MACH SYST, V44, P537, DOI 10.1109/THMS.2014.2320277; Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005; Gu T, 2011, IEEE T KNOWL DATA EN, V23, P1359, DOI 10.1109/TKDE.2010.184; Guo L, 2013, PATTERN RECOGN LETT, V34, P603, DOI 10.1016/j.patrec.2013.01.003; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Ordonez FJ, 2014, IEEE PERVAS COMPUT, V13, P67, DOI 10.1109/MPRV.2014.52; Li J, 2017, INFORM FUSION, V35, P1, DOI 10.1016/j.inffus.2016.08.001; Lichman M, 2013, UCI MACHINE LEARNING; Liggins M. E., 2017, HDB MULTISENSOR DATA; Liu N, 2010, IEEE SIGNAL PROC LET, V17, P754, DOI 10.1109/LSP.2010.2053356; Lu Z. Y., 2010, P 16 ACM SIGKDD INT, P871, DOI DOI 10.1145/1835804.1835914>; Margineantu D. D., 1997, 14 INT C MACH LEARN; Martinez-Munoz G, 2009, IEEE T PATTERN ANAL, V31, P245, DOI 10.1109/TPAMI.2008.78; Martinez-Munoz G., 2004, AGGREGATION ORDERING, P258; Omari A, 2015, INFORM FUSION, V26, P96, DOI 10.1016/j.inffus.2015.01.003; Roggen D, 2010, 2010 Seventh International Conference on Networked Sensing Systems (INSS 2010), P233, DOI 10.1109/INSS.2010.5573462; Sagha H, 2011, IEEE SYS MAN CYBERN, P36, DOI 10.1109/ICSMC.2011.6083628; Sakar CO, 2012, EXPERT SYST APPL, V39, P3432, DOI 10.1016/j.eswa.2011.09.031; Shao WM, 2017, NEUROCOMPUTING, V222, P91, DOI 10.1016/j.neucom.2016.10.005; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Stikic M, 2011, IEEE T PATTERN ANAL, V33, P2521, DOI 10.1109/TPAMI.2011.36; Tao DP, 2014, IEEE T IND INFORM, V10, P813, DOI 10.1109/TII.2013.2255061; Unler A, 2011, INFORM SCIENCES, V181, P4625, DOI 10.1016/j.ins.2010.05.037; Wang XL, 2014, NEUROCOMPUTING, V128, P31, DOI 10.1016/j.neucom.2013.02.053; Ye J, 2015, PERVASIVE MOB COMPUT, V19, P47, DOI 10.1016/j.pmcj.2014.02.003; Ykhlef H, 2017, INFORM FUSION, V34, P28, DOI 10.1016/j.inffus.2016.06.003; Zappi P, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING, P281, DOI 10.1109/ISSNIP.2007.4496857; Zhou Z., 2012, ENSEMBLE METHODS FDN; Zhu C, 2011, IEEE T SYST MAN CY A, V41, P569, DOI 10.1109/TSMCA.2010.2093883; Zhu HY, 2014, INFORM FUSION, V20, P203, DOI 10.1016/j.inffus.2014.02.002	44	0	0	31	31	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	MAY	2018	41						68	79		10.1016/j.inffus.2017.08.002				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	FP5LX	WOS:000417662100008					2018-01-30	
J	Hassan, MM; Huda, S; Yearwood, J; Jelinek, HF; Almogren, A				Hassan, Mohammad Mehedi; Huda, Shamsul; Yearwood, John; Jelinek, Herbert F.; Almogren, Ahmad			Multistage fusion approaches based on a generative model and multivariate exponentially weighted moving average for diagnosis of cardiovascular autonomic nerve dysfunction	INFORMATION FUSION			English	Article						Fusion of multiple statistical process control techniques; Multivariate exponentially weighted moving average; Autonomic nerve dysfunction classification; Blind source separation; Fusion of features and decisions	MACHINE LEARNING ALGORITHMS; STOCK-MARKET; NEUROPATHY; MANAGEMENT	Like many medical diagnoses, clinical decision support system (CDSS) is essential to diagnose the cardiovascular autonomic neuropathy (CAN). However, diagnosis of CAN using the traditional 'Ewing battery test' becomes very difficult due to the inherent imbalanced and incompleteness condition in the collected clinical data. This influences the health professionals to investigate other related diagnostic reports of patients, including Electrocardiogram (ECG) data from ECG sensors, blood chemistry, podiatry and endocrinology features. However, additional components increase the dimensionality of the feature set as well as its heterogeneity and modality in the clinical data which may limit the applications of traditional data mining approaches for an accurate diagnosis of CAN in the CDSS. To address the aforementioned problem, in this paper, we have proposed, a novel multistage fusion approach based on a generative model and a statistical process control (SPC) technique to diagnose CAN more accurately. The proposed approach develops two different generative models by using a shared and a separated Independent Component Analysis (ICA) to overcome the incompleteness and modality of the data. Due to the heterogeneous and non-normality features, statistical correlations and multivariate control limits in relation to the CAN diagnosis parameters are determined by fusioning of a series of exponentially weighted moving average (MEWMA) control processes. Fusioned features from both component analyses and SPC are applied in an ensemble classification system. The proposed multistage fusion approach is experimentally verified to justify its performance by using a large dataset collected from the diabetes screening research initiative (DiScRi) project at Charles Sturt University, NSW, Australia. Our comprehensive experimental results show that the proposed fusion approach performs better than the standard classifier for both 'Ewing' feature set and 'Ewing and additional feature set' with significant improvement in accuracy. (C) 2017 Elsevier B.V. All rights reserved.	[Hassan, Mohammad Mehedi; Almogren, Ahmad] King Saud Univ, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia; [Huda, Shamsul; Yearwood, John] Deakin Univ, Sch IT, Geelong, Vic, Australia; [Jelinek, Herbert F.] Charles Sturt Univ, Sch Community Hlth, Bathurst, NSW, Australia	Hassan, MM (reprint author), King Saud Univ, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.	mmhassan@ksu.edu.sa; shamsul.huda@deakin.edu.au; john.yearwood@deakin.edu.au; ahalmogren@ksu.edu.sa			Deanship of Scientific Research at King Saud University [RGP-1437-35]	The authors would like to extend their sincere appreciation to the Deanship of Scientific Research at King Saud University for funding this research through Research Group Project No. RGP-1437-35.	[Anonymous], 1988, DIABETES CARE, V11, P592; Gravina R., 2010, WEARABLE AUTONOMOUS, V75, P369; Ankishan H., 2013, COMPUT MATH METHOD M, V2013; Antink CH, 2015, BIOMED OPT EXPRESS, V6, P2895, DOI 10.1364/BOE.6.002895; Barak S, 2017, INFORM FUSION, V36, P90, DOI 10.1016/j.inffus.2016.11.006; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Chanudet X, 2007, DIABETES METAB, V33, pS19, DOI 10.1016/S1262-3636(07)80054-1; Chen CJ, 2016, INFORM FUSION, V32, P80, DOI 10.1016/j.inffus.2015.09.005; Chiu CC, 2014, J MED BIOL ENG, V34, P495, DOI 10.5405/jmbe.1573; Cohen JA, 2003, AUTON NEUROSCI-BASIC, V108, P73, DOI 10.1016/j.autneu.2003.07.001; Correa NM, 2010, IEEE SIGNAL PROC MAG, V27, P39, DOI 10.1109/MSP.2010.936725; Cortex M., HDB CLIN NEUROLOGY, V126; Dimova R., 2016, J DIABETES COMPLICAT; EWING DJ, 1982, BRIT MED J, V285, P916, DOI 10.1136/bmj.285.6346.916; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fortino G, 2013, IEEE T HUM-MACH SYST, V43, P115, DOI 10.1109/TSMCC.2012.2215852; Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005; Gravina R, 2016, IEEE T AFFECT COMPUT, V7, P286, DOI 10.1109/TAFFC.2016.2515094; Hashimoto H., 2013, 12 IFAC S COMP APPL, P16; Hsu C., 2016, IEEE T SYST MAN CY B, V32; Huda S., 2010, 6 INT C INT SENS SEN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koldovsky Z, 2006, IEEE T NEURAL NETWOR, V17, P1265, DOI 10.1109/TNN.2006.875991; Liu JY, 2009, HUM BRAIN MAPP, V30, P241, DOI 10.1002/hbm.20508; lyengar S., 2008, BODYNETS, V8, P1; Mayhua-Lopez E, 2015, INFORM FUSION, V25, P63, DOI 10.1016/j.inffus.2014.10.005; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Orphanidou C, 2013, BIOMED SIGNAL PROCES, V8, P98, DOI 10.1016/j.bspc.2012.06.001; PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532; Patel J, 2015, EXPERT SYST APPL, V42, P2162, DOI 10.1016/j.eswa.2014.10.031; Pearlmutter BA., 1996, P INT C NEUR INF PRO; Pinto AR, 2014, INFORM FUSION, V15, P90, DOI 10.1016/j.inffus.2013.05.003; Prince CT, 2010, DIABETES CARE, V33, P652, DOI 10.2337/dc09-1936; Prince C. T., 2016, LIPIDS HLTH DIS, V122; Pujar S, 2010, EPILEPSY RES, V91, P205, DOI 10.1016/j.eplepsyres.2010.07.013; Sibrava NJ, 2016, J ANXIETY DISORD, V42, P45, DOI 10.1016/j.janxdis.2016.05.005; Sood A, 2014, EUR UROL, V66, P371, DOI 10.1016/j.eururo.2014.02.055; Spallone V, 1997, DIABETES RES CLIN PR, V34, P169, DOI 10.1016/S0168-8227(96)01354-X; Tennant R, 2007, INT J QUAL HEALTH C, V19, P187, DOI 10.1093/intqhc/mzm015; Tsai CF, 2014, INFORM FUSION, V16, P46, DOI 10.1016/j.inffus.2011.12.001; Zou CL, 2007, TECHNOMETRICS, V49, P395, DOI 10.1198/004017007000000164	41	0	0	57	57	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	MAY	2018	41						105	118		10.1016/j.inffus.2017.08.004				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	FP5LX	WOS:000417662100011					2018-01-30	
J	Carcillo, F; Dal Pozzolo, A; Le Borgne, YA; Caelen, O; Mazzer, Y; Bontempi, G				Carcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Ael; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca			SCARFF: A scalable framework for streaming credit card fraud detection with spark	INFORMATION FUSION			English	Article						Big data; Fraud detection; Streaming analytics; Machine learning; Scalable software; Kafka; Spark; Cassandra	EVOLVING DATA STREAMS; BIG DATA; CONCEPT-DRIFT; CLASSIFIERS; FOREST	The expansion of the electronic commerce, together with an increasing confidence of customers in electronic payments, makes of fraud detection a critical factor. Detecting frauds in (nearly) real time setting demands the design and the implementation of scalable learning techniques able to ingest and analyse massive amounts of streaming data. Recent advances in analytics and the availability of open source solutions for Big Data storage and processing open new perspectives to the fraud detection field. In this paper we present a Scalable Real-time Fraud Finder (SCARFF) which integrates Big Data tools (Kafka, Spark and Cassandra) with a machine learning approach which deals with imbalance, nonstationarity and feedback latency. Experimental results on a massive dataset of real credit card transactions show that this framework is scalable, efficient and accurate over a big stream of transactions. (C) 2017 Elsevier B.V. All rights reserved.	[Carcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Ael; Bontempi, Gianluca] ULB, Fac Sci, Comp Sci Dept, Machine Learning Grp, Brussels, Belgium; [Caelen, Olivier; Mazzer, Yannis] Worldline, R&D High Proc & Volume Team, Brussels, Belgium	Carcillo, F (reprint author), ULB, Fac Sci, Comp Sci Dept, Machine Learning Grp, Brussels, Belgium.	fcarcill@ulb.ac.be; dalpozz@gmail.com; yleborgn@ulb.ac.be; olivier.caelen@worldline.com; yannis.mazzer@worldline.com; gbonte@ulb.ac.be			Brufence project (scalable machine learning for automating defense system) - INNOVIRIS (Brussels Institute for the encouragement of scientific research and innovation); Doctiris (Adaptive real-time machine learning for credit card fraud detection) project - INNOVIRIS (Brussels Institute for the encouragement of scientific research and innovation)	The authors FC, YLB and GB acknowledge the funding of the Brufence project (scalable machine learning for automating defense system) supported by INNOVIRIS (Brussels Institute for the encouragement of scientific research and innovation). ADP acknowledges the funding of the Doctiris (Adaptive real-time machine learning for credit card fraud detection) project supported by INNOVIRIS (Brussels Institute for the encouragement of scientific research and innovation).	Abdallah ZS, 2016, EVOL SYST, V7, P73, DOI 10.1007/s12530-016-9147-7; Akidau T., 2013, MILLWHEEL FAULT TOLE, P734; Alippi C, 2013, IEEE T NEUR NET LEAR, V24, P620, DOI 10.1109/TNNLS.2013.2239309; Bahnsen AC, 2016, EXPERT SYST APPL, V51, P134, DOI 10.1016/j.eswa.2015.12.030; Bahnsen AC, 2015, EXPERT SYST APPL, V42, P6609, DOI 10.1016/j.eswa.2015.04.042; Bhattacharyya S, 2011, DECIS SUPPORT SYST, V50, P602, DOI 10.1016/j.dss.2010.08.008; Bifet A, 2010, LECT NOTES ARTIF INT, V6119, P299; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen C., 2004, USING RANDOM FOREST, V110; Chen J., 2015, J FINANCE DATA SCI, V1, P1; Dal Pozzolo A, 2014, IEEE IJCNN, P588, DOI 10.1109/IJCNN.2014.6889638; Dal Pozzolo A, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P159, DOI 10.1109/SSCI.2015.33; Dal Pozzolo A, 2015, LECT NOTES ARTIF INT, V9284, P200, DOI 10.1007/978-3-319-23528-8_13; Dal Pozzolo A, 2014, EXPERT SYST APPL, V41, P4915, DOI 10.1016/j.eswa.2014.02.026; Dal Pozzolo A, 2015, THESIS; Dal Pozzolo A., 2015, P INT JOINT C NEUR N, P1; Boracchi G., 2017, IEEE T NEUR IN PRESS; del Rio S, 2014, INFORM SCIENCES, V285, P112, DOI 10.1016/j.ins.2014.03.043; Fan GZ, 2011, STAT INTERFACE, V4, P11; Faria ER, 2016, ARTIF INTELL REV, V45, P235, DOI 10.1007/s10462-015-9444-8; Friedman J., 2001, SPRINGER SERIES STAT, V1; Gama J, 2000, MACH LEARN, V41, P315, DOI 10.1023/A:1007652114878; Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813; Ghosh S., 1994, Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences. Vol.III: Information Systems: Decision Support and Knowledge-Based Systems (Cat. No.94TH0607-2), P621, DOI 10.1109/HICSS.1994.323314; Gomes HM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054925; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Hormozi E, 2013, 2013 5TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P35, DOI 10.1109/IKT.2013.6620034; Hormozi H, 2013, 2013 5TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P40, DOI 10.1109/IKT.2013.6620035; Krawczyk Bartosz, 2016, Progress in Artificial Intelligence, V5, P221, DOI 10.1007/s13748-016-0094-0; Krawczyk B, 2017, INFORM FUSION, V37, P132, DOI 10.1016/j.inffus.2017.02.004; Krawczyk B, 2015, SOFT COMPUT, V19, P3387, DOI 10.1007/s00500-014-1492-5; Krawczyk B, 2015, J COMPUT SCI-NETH, V9, P19, DOI 10.1016/j.jocs.2015.04.024; Kreps J., 2011, P NETDB, P1; Lakshman Avinash, 2010, Operating Systems Review, V44, P35, DOI 10.1145/1773912.1773922; Lin Q., 2015, SIGMOD, P811; Meng X., 2015, ARXIV150506807; Odersky M., 2004, IC200464 EPFL LAUS; Phulari S., 2016, INT J ENG SCI INNOV, V5, P92; Ramirez-Gallego S, 2017, NEUROCOMPUTING, V239, P39, DOI 10.1016/j.neucom.2017.01.078; Rokach L, 2016, INFORM FUSION, V27, P111, DOI 10.1016/j.inffus.2015.06.005; Sahin Y, 2013, EXPERT SYST APPL, V40, P5916, DOI 10.1016/j.eswa.2013.05.021; Sanchez D, 2009, EXPERT SYST APPL, V36, P3630, DOI 10.1016/j.eswa.2008.02.001; Triguero I, 2015, KNOWL-BASED SYST, V87, P69, DOI 10.1016/j.knosys.2015.05.027; Tselykh A., 2015, P 8 INT C SEC INF NE, P114; Van Vlasselaer V, 2015, DECIS SUPPORT SYST, V75, P38, DOI 10.1016/j.dss.2015.04.013; Vavilapalli V. K., 2013, SOCC 13, V5, P1, DOI DOI 10.1145/2523616.2523633; Veeramachaneni K, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P49, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.79; Viaene S, 2004, IEEE T KNOWL DATA EN, V16, P612, DOI 10.1109/TKDE.2004.1277822; Whitrow C, 2009, DATA MIN KNOWL DISC, V18, P30, DOI 10.1007/s10618-008-0116-z; Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006; Yang H, 2015, J SYST SOFTWARE, V102, P158, DOI 10.1016/j.jss.2014.07.010; Yang H, 2013, IEEE INT CONGR BIG, P126, DOI 10.1109/BigData.Congress.2013.25; Zaharia M., 2010, HOTCLOUD, V10, P10, DOI DOI 10.HTTP://DL.ACM.0RG/CITATI0N.CFM?; Zaharia M., 2012, HOTCLOUD, V12, P10; Zaharia M., 2012, P 9 USENIX C NETW SY, P2, DOI DOI 10.1145/1057977.1057978	55	0	0	34	34	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	MAY	2018	41						182	194		10.1016/j.inffus.2017.09.005				13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	FP5LX	WOS:000417662100017					2018-01-30	
J	Boroumand, M; Fridrich, J				Boroumand, Mehdi; Fridrich, Jessica			Applications of Explicit Non-Linear Feature Maps in Steganalysis	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						Steganalysis; adaptive steganography; explicit transformation; Nystrom approximation; support vector machine	DIGITAL IMAGE STEGANALYSIS; STEGANOGRAPHY; PROJECTIONS; MODEL	Currently, the most popular detectors of content-adaptive image steganography are built using machine learning with images represented with rich features. Such high-dimensional descriptors, however, prevent utilization of more complex and potentially more accurate machine learning paradigms, such as kernelized support vector machines, due to infeasibly expensive training. In this paper, we demonstrate that explicit non-linear feature maps coupled with simple classifiers improve the accuracy of current steganalysis detectors built as binary classifiers as well as quantitative detectors in the form of payload regressors. The non-linear map is obtained by approximating a symmetric positive semi-definite kernel on selected pairs of cover features. Exponential forms of kernels derived from symmetrized Ali-Silvey distances improve the detection accuracy of binary detectors and lower the error of quantitative detectors across all tested steganographic schemes on grayscale and color images. The learned non-linear map only weakly depends on the cover source and its learning has a low computational complexity. The technique can also be used for unsupervised feature dimensionality reduction. For payload regressors, the dimensionality can be significantly reduced while simultaneously decreasing the estimation error.	[Boroumand, Mehdi; Fridrich, Jessica] Binghamton Univ, Dept Elect & Comp Engn, Binghamton, NY 13902 USA	Boroumand, M (reprint author), Binghamton Univ, Dept Elect & Comp Engn, Binghamton, NY 13902 USA.	mboroum1@binghamton.edu; fridrich@binghamton.edu			Air Force Office of Scientific Research [FA9550-09-1-0147]	This work was supported by the Air Force Office of Scientific Research under Grant FA9550-09-1-0147.	Abdulrahman H, 2016, SECUR COMMUN NETW, V9, P2945, DOI 10.1002/sec.1427; ALI SM, 1966, J ROY STAT SOC B, V28, P131; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Bo L., 2009, P ADV NEUR INF PROC, P135; Boroumand M., 2016, P 4 ACM WORKSH INF H, P149; Boroumand M., 2017, P 5 ACM IHMMSEC WORK, P8; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Chaumont M, 2012, IEEE IMAGE PROC, P1133, DOI 10.1109/ICIP.2012.6467064; Chen L., 2014, P 13 INT WORKSH DIG, P559; CHEN LQ, 2013, PROC INT WORKSH DIG, V344, P19, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/DDF.344.19; Cogranne R., 2015, P IEEE INT WORKSH IN, P1; Cogranne R, 2015, IEEE T INF FOREN SEC, V10, P2627, DOI 10.1109/TIFS.2015.2470220; Cozzolino D., 2015, IEEE INT WORKSH INF, P1; Denemark T., 2016, ELECT IMAGING, V2016, P1; Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281; Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302; Filler T., 2010, BOSS BREAK OUR STEGA; Fong DCL, 2011, SIAM J SCI COMPUT, V33, P2950, DOI 10.1137/10079687X; Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P102, DOI 10.1007/978-3-642-24178-9_8; Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402; Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3; Goljan M, 2014, IEEE INT WORKS INFOR, P185, DOI 10.1109/WIFS.2014.7084325; Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817; Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644; Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1; Holub V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2075239; Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918; Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682; Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655; Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1; Kodovsky J, 2013, P IEEE ICASSP, V8665, P1; Kodovsky J., 2011, P SPIE ELECT IMAGING, V7880, P1; Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919; Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854; Lubenko I., 2012, P 13 ACM WORKSH MULT, P11; Pasquet J, 2014, EUR SIGNAL PR CONF, P2425; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Pevny T., 2013, P IS T SPIE EL IM, V8665, P1; PEVNY T, 2010, P 12 INF HID, V6387, P161; Pevny T, 2012, IEEE T INF FOREN SEC, V7, P445, DOI 10.1109/TIFS.2011.2175918; Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479; Raginsky M, 2009, P ADV NEUR INF PROC, P1509; Rahimi A., 2008, ADV NEURAL INFORM PR, P1177; Scholkopf Bernhard, 2001, LEARNING KERNELS SUP; Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744; Song X., 2015, P 3 ACM WORKSH INF H, P15; Tang W., 2014, P 2 ACM WORKSH INF H, P91; Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wang PF, 2017, SOFT COMPUT, V21, P3335, DOI 10.1007/s00500-015-2011-z; Westfeld A, 2001, INFORM HIDING, P289; Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421	52	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-6013	1556-6021		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	APR	2018	13	4					823	833		10.1109/TIFS.2017.2766580				11	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	FS1KY	WOS:000419535900001					2018-01-30	
J	Gunasinghe, H; Bertino, E				Gunasinghe, Hasini; Bertino, Elisa			PrivBioMTAuth: Privacy Preserving Biometrics-Based and User Centric Protocol for User Authentication From Mobile Phones	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						Biometrics; authentication; privacy; security; identity management systems	FUZZY EXTRACTORS; SKETCHES	We introduce a privacy preserving biometrics-based authentication solution by which users can authenticate to different service providers from mobile phones without involving identity providers in the transactions. Authentication is performed via zero-knowledge proof of knowledge, based on a cryptographic identity token that encodes the biometric identifier of the user and a secret provided by the user, making it three-factor authentication. Our approach for generating a unique, repeatable, and revocable biometric identifier from the user's biometric image is based on a machine learning-based classification technique, which involves the features extracted from the user's biometric image. We have implemented a prototype of the proposed authentication solution and evaluated our solution with respect to its performance, security, and privacy. The evaluation has been performed on a public data set of face images.	[Gunasinghe, Hasini; Bertino, Elisa] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Gunasinghe, H (reprint author), Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.	huralali@purdue.edu; bertino@purdue.edu					Asokan N., 2013, LECT NOTES COMPUTER, V7859; AT&T, 2002, DAT FAC; Barni M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P231; Bhargav-Spantzel A., 2010, P 9 S ID TRUST GAITH, P84; Blanton M., 2011, LECT NOTES COMPUTER, V6879; Blanton M, 2013, IEEE T INF FOREN SEC, V8, P1433, DOI 10.1109/TIFS.2013.2272786; Cappella N., 2016, HSBC ANNOUNCES BIOME; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chaum D., 1987, EUROCRYPT 87, P127; Chun H., 2014, P 9 ACM S INF COMP C, P401; Crouse D, 2015, INT CONF BIOMETR, P135, DOI 10.1109/ICB.2015.7139043; De Cristofaro E, 2010, LECT NOTES COMPUT SC, V6052, P143, DOI 10.1007/978-3-642-14577-3_13; Desmedt Y., 1987, P ADV CRYPT CRYPTO 8, P21; Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523; Erkin Z., 2009, LECT NOTES COMPUTER, V5672; Feige U., 1988, Journal of Cryptology, V1, P77, DOI 10.1007/BF02351717; FIAT A, 1987, LECT NOTES COMPUT SC, V263, P186; Gofman MI, 2016, COMMUN ACM, V59, P58, DOI 10.1145/2818990; GSMARENA, MOT MOT G FULL PHON; Gunasinghe H., 2017, 20174 CERIAS TR; Gunasinghe H., 2014, P 8 INT C NETW SYST, P15; Huang Y., 2011, P IEEE 45 ANN C INF, P1, DOI DOI 10.1109/ICC.2011.5962706; Jain A., 2015, PERV COMP ICPC 2015, P1; Java-Matrix-Benchmark, RUNT INT COR I7 2600; Kostiainen K., 2009, P 4 INT S INF COMP C, P104; MacGregor A., 2016, AMAZON WANTS REPLACE; MacGregor A., 2016, SECURITY RICH INTERN; Narasimha M, 2009, INT J INF SECUR, V8, P61, DOI 10.1007/s10207-008-0064-z; Paci F, 2008, LECT NOTES COMPUT SC, V5287, P268; Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151; Pedersen T. P., 1991, CRYPTO 91, P129; Peeters R., 2013, P 3 POL RES ID MAN I, P18; Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3; Scott M., M PIN MULTIFACTOR ZE; Senior A., BIOMETRICS SHORT COU; Simoens K, 2009, P IEEE S SECUR PRIV, P188, DOI 10.1109/SP.2009.24; SOLIS J, 2006, PROC 6 INT CONF, V4258, P351; Stack Overflow, 2015, PERF JAV MATR MATH L; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71	39	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-6013	1556-6021		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	APR	2018	13	4					1042	1057		10.1109/TIFS.2017.2777787				16	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	FS1KY	WOS:000419535900018					2018-01-30	
J	Lu, JS; Cheng, MY; Su, KH; Tsai, MC				Lu, Jie-Shiou; Cheng, Ming-Yang; Su, Ke-Han; Tsai, Mi-Chi			Wire tension control of an automatic motor winding machine-an iterative learning sliding mode control approach	ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING			English	Article						Wire tension control; Iterative learning control; Sliding mode control; Motor winding process; Disturbance observer	ROBOT MANIPULATORS; FRICTION; SYSTEM; COMPENSATION; DESIGN; OBSERVER	One of the most crucial factors that affects the winding quality in an automatic motor winding process is the regulation of wire tension. Most commercial automatic motor winding machines use passive devices such as a dancer arm or a hysteresis brake to adjust the wire tension. However, as the winding speed increases, these passive devices may not be able to react quickly enough to maintain constant wire tension and may cause the enameled wire to tremble. In order to cope with the aforementioned problems, this paper conducts an in-depth study on active wire tension control of automatic motor winding machines. In particular, an iterative learning sliding mode control scheme for wire tension control is developed in this paper, while a disturbance observer is employed to estimate the wire tension for the implementation of sensorless wire tension control. Moreover, due to the fact that the motion of the unwind roll is affected by the motion of the enameled wire, the estimated wire speed information is exploited in the design of the tension control scheme to lessen the lag phenomenon. Results of the winding experiments verify the effectiveness of the proposed wire tension control scheme. (C) 2017 Elsevier Ltd. All rights reserved.	[Lu, Jie-Shiou; Cheng, Ming-Yang; Su, Ke-Han] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 701, Taiwan; [Tsai, Mi-Chi] Natl Cheng Kung Univ, Dept Mech Engn, Tainan 701, Taiwan	Cheng, MY (reprint author), Natl Cheng Kung Univ, Dept Elect Engn, Tainan 701, Taiwan.	mycheng@mail.ncku.edu.tw			Ministry of Economic Affairs (MOEA) of Taiwan; National Science Council of Taiwan [MORA102-EC-17-A-05-S1-192, NSC 102-2221-E-006-204]	The authors would like to thank the Ministry of Economic Affairs (MOEA) of Taiwan and the National Science Council of Taiwan, for their support of this research under grant nos. MORA102-EC-17-A-05-S1-192, and NSC 102-2221-E-006-204.	Abjadi NR, 2009, IET CONTROL THEORY A, V3, P419, DOI 10.1049/iet-cta.2008.0118; Ahn HS, 2007, IEEE T SYST MAN CY C, V37, P1099, DOI 10.1109/TSMCC.2007.905759; ARIMOTO S, 1984, J ROBOTIC SYST, V1, P123, DOI 10.1002/rob.4620010203; Barton KL, 2008, IEEE T CONTR SYST T, V16, P1218, DOI 10.1109/TCST.2008.919433; Bristow DA, 2006, IEEE CONTR SYST MAG, V26, P96, DOI 10.1109/MCS.2006.1636313; Chen WJ, 2014, IEEE T CONTR SYST T, V22, P1350, DOI 10.1109/TCST.2013.2279652; Chien CJ, 2008, AUTOMATICA, V44, P830, DOI 10.1016/j.automatica.2007.06.023; De Roover D, 2000, INT J CONTROL, V73, P968, DOI 10.1080/002071700405923; Dodds Stephen J., 2011, 2011 IEEE 20th International Symposium on Industrial Electronics (ISIE 2011), P1925, DOI 10.1109/ISIE.2011.5984452; Dong Sun, 1999, Proceedings of the 1999 American Control Conference (Cat. No. 99CH36251), P1935, DOI 10.1109/ACC.1999.786195; ELCI H, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS - HUMANS, INFORMATION AND TECHNOLOGY, VOLS 1-3, P2767, DOI 10.1109/ICSMC.1994.400292; Freeman CT, 2012, IEEE CONTR SYST MAG, V32, P18, DOI 10.1109/MCS.2011.2173261; Garimella SS, 1998, IEEE T CONTR SYST T, V6, P281, DOI 10.1109/87.664194; Gassmann V, 2012, IEEE T CONTR SYST T, V20, P173, DOI 10.1109/TCST.2011.2107554; Ghosh J, 2002, IEEE T AUTOMAT CONTR, V47, P831, DOI 10.1109/TAC.2002.1000282; Jie-Shiou Lu, 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P1643, DOI 10.1109/InfoSEEE.2014.6946200; JOHNSON CT, 1992, IEEE T IND APPL, V28, P1392, DOI 10.1109/28.175293; Knittel D, 2003, IEEE T IND APPL, V39, P113, DOI 10.1109/TIA.2002.807231; Lee JU, 2000, IEEE IND APPLIC SOC, P2662, DOI 10.1109/IAS.2000.883199; Li Q, 2016, INT J ADV MANUF TECH, V82, P1089, DOI 10.1007/s00170-015-7412-8; Lin KC, 2001, IEEE IND ELEC, P529, DOI 10.1109/IECON.2001.976539; Longman RW, 2000, INT J CONTROL, V73, P930, DOI 10.1080/002071700405905; Mainali K, 2004, ICM '04: PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS 2004, P352, DOI 10.1109/ICMECH.2004.1364464; Nevaranta N., 2012, P IEEE INT C POW EL; Owens DH, 2005, ANNU REV CONTROL, V29, P57, DOI 10.1016/j.arcontrol.2005.01.003; Slotine J., 1991, APPL NONLINEAR CONTR; Su K.-H., 2012, P 5 INT C POS TECHN, P107; Sun MX, 2006, IEEE T ROBOT, V22, P563, DOI 10.1109/TRO.2006.870650; Tayebi A, 2006, CONTROL ENG PRACT, V14, P843, DOI 10.1016/j.conengprac.2005.04.013; Tayebi A, 2004, AUTOMATICA, V40, P1195, DOI 10.1016/j.automatica.2004.01.026; Tsai MC, 2000, CONTROL ENG PRACT, V8, P259, DOI 10.1016/S0967-0661(99)00160-4; Tsai MS, 2006, IEEE T CONTR SYST T, V14, P511, DOI 10.1109/TCST.2005.860521; UTKIN VI, 1993, IEEE T IND ELECTRON, V40, P23, DOI 10.1109/41.184818; Visioli A, 2010, IEEE T ROBOT, V26, P388, DOI 10.1109/TRO.2010.2041265; Wang C, 2015, ROBOT CIM-INT MANUF, V35, P96, DOI 10.1016/j.rcim.2015.03.002; Wang CX, 2004, IEEE T IND ELECTRON, V51, P381, DOI 10.1109/TIE.2003.822096; Wang YQ, 2009, J PROCESS CONTR, V19, P1589, DOI 10.1016/j.jprocont.2009.09.006; Wankun Zhou, 2007, 16th IEEE International Conference on Control Applications. Part of IEEE Multi-conference on Systems and Control, P842; Zhao H., 2008, ASME J DYN SYST MEAS, V130	39	0	0	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0736-5845	1879-2537		ROBOT CIM-INT MANUF	Robot. Comput.-Integr. Manuf.	APR	2018	50						50	62		10.1016/j.rcim.2017.09.003				13	Computer Science, Interdisciplinary Applications; Engineering, Manufacturing; Robotics	Computer Science; Engineering; Robotics	FR9VG	WOS:000419420600005					2018-01-30	
J	Deng, N; Li, X				Deng, Ning; Li, Xiang (Robert)			Feeling a destination through the "right" photos: A machine learning model for DMOs' photo selection	TOURISM MANAGEMENT			English	Article						UGC photos; Flickr; Destination image; Data mining; Photo recommendation	SOCIAL CONSTRUCTION; IMAGE; TOURISTS; PLACES	Photos are important carriers in destination image communication. Currently, efficiently selecting appropriate photos for destination promotion remains a major challenge for DMOs, a problem closely related to the discrepancy between projected and received destination images. During the photo selection process, contents that can best evoke viewers' potential motives should be considered favorably. This project proposes and implements a machine learning-based model to assist DMOs with photo content selection. The proposed protocol ranks candidate photos describing a specific theme from viewers' perspective. In the present empirical study, over 20,000 Flickr photos of New York City taken by foreign tourists were analyzed to demonstrate the effectiveness of this approach. The results indicate that the proposed method can facilitate the selection of destination photos and address the pronounced gap between projected and received images. (C) 2017 Elsevier Ltd. All rights reserved.	[Deng, Ning] Beijing Int Studies Univ, Sch Tourism Management, Dept Tourism Ecommerce & Mkt, Beijing 100024, Peoples R China; [Li, Xiang (Robert)] Temple Univ, Sch Tourism & Hospitality Management, Philadelphia, PA 19121 USA	Deng, N (reprint author), Beijing Int Studies Univ, Sch Tourism Management, Dept Tourism Ecommerce & Mkt, Beijing 100024, Peoples R China.	dengning@bisu.edu.cn; robertli@temple.edu			National Natural Science Foundation of China [71502005]; Philosophy and Social Science Foundation of Beijing [17JDGLB006]	Thanks to National Natural Science Foundation of China (71502005) and Philosophy and Social Science Foundation of Beijing (17JDGLB006) for supporting this research.	Agrawal Rakesh, 2009, P 2 ACM INT C WEB SE, P5, DOI DOI 10.1145/1498759.1498766; Amaro S, 2016, ANN TOURISM RES, V59, P1, DOI 10.1016/j.annals.2016.03.007; ANAND P, 1988, J CONSUM RES, V15, P386, DOI 10.1086/209176; Baloglu S, 1999, ANN TOURISM RES, V26, P868, DOI 10.1016/S0160-7383(99)00030-4; Baloglu S., 1997, Journal of Travel Research, V35, P11; Baloglu S., 1997, J VACAT MARK, V3, P221, DOI DOI 10.1177/135676679700300304; Bramwell B, 1996, ANN TOURISM RES, V23, P201, DOI 10.1016/0160-7383(95)00061-5; Caton K, 2008, ANN TOURISM RES, V35, P7, DOI 10.1016/j.annals.2007.03.014; Chen T, 2014, ARXIV14108586; Chen YY, 2014, P ACM INT C MULT RET, P233; Court B., 1997, Journal of Travel Research, V36, P35, DOI 10.1177/004728759703600106; Donaire JA, 2011, CUAD TUR, P291; Lopes SDF, 2011, PASOS, V9, P305; Fotis J., 2012, SOCIAL MEDIA USE IMP; Garrod B., 2008, J TRAVEL RES; Gartner W. C., 1993, Journal of Travel & Tourism Marketing, V2, P191; Hollenstein L, 2010, J SPAT INT SCI, P21, DOI 10.5311/JOSIS.2010.1.3; Hsu CHC, 2012, ASIA PAC J TOUR RES, V17, P577, DOI 10.1080/10941665.2011.630674; Hunter WC, 2016, TOURISM MANAGE, V54, P221, DOI 10.1016/j.tourman.2015.11.012; Jenkins O. H., 2003, Tourism Geographies, V5, P305, DOI 10.1080/14616680309715; Ji S., 2011, PROJECTED PERCEIVED; Kim H, 2003, ANN TOURISM RES, V30, P216, DOI 10.1016/S0160-7383(02)00062-2; Kim H, 2015, TOURISM MANAGE, V49, P29, DOI 10.1016/j.tourman.2015.02.004; Kozma G., 1993, GRONINGEN STUDIES, P55; Lai K., 2015, J TRAVEL RES; Li X. R., 2009, J TRAVEL RES; Li X. R., 2011, J TRAVEL RES; Lim K. H, 2015, P 2015 ACM SIGMOD PH, P33; Lin ChungHsien, 2007, Journal of Travel Research, V46, P183, DOI 10.1177/0047287506304049; Lo IS, 2011, TOURISM MANAGE, V32, P725, DOI 10.1016/j.tourman.2010.06.001; Loris S, 2014, TEXTBLOB SIMPLIFIED; Machaj J, 2010, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE, RADIOELETRONIKA 2010, P83, DOI 10.1145/1873951.1873965; MacKay K. J., 2004, Journal of Travel Research, V42, P390, DOI 10.1177/0047287504263035; McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41; Pan S, 2014, TOURISM MANAGE, V40, P59, DOI 10.1016/j.tourman.2013.05.007; Pang B., 2002, EMP METH NAT LANG PR; Pengiran-Kahar DINF, 2010, INFORMATION AND COMMUNICATION TECHNOLOGIES IN TOURISM 2010, P543, DOI 10.1007/978-3-211-99407-8_45; Popescu Adrian, 2009, P 18 ACM C INF KNOWL, P1713; Smith WW, 2015, TOURISM MANAGE, V48, P113, DOI 10.1016/j.tourman.2014.04.010; Song SG, 2016, J TRAVEL TOUR MARK, V33, P687, DOI 10.1080/10548408.2016.1167384; Stepchenkova S, 2015, J TRAVEL RES, V54, P758, DOI 10.1177/0047287514535849; Stepchenkova S, 2013, TOURISM MANAGE, V36, P590, DOI 10.1016/j.tourman.2012.08.006; STERN E, 1993, GEOGR ANAL, V25, P130; Stylianou-Lambert T, 2012, ANN TOURISM RES, V39, P1817, DOI [10.1016/j.anna1s.2012.05.004, 10.1016/j.annals.2012.05.004]; Tasci A. D. A., 2007, Journal of Travel Research, V45, P413, DOI 10.1177/0047287507299569; Urry J., 2002, TOURIST GAZE; WANG WN, 2008, IEEE IMAGE PROC, P117; White L., 2009, TOURISM INFORM VISUA, P115; Young M, 1999, AUST GEOGR, V30, P373, DOI 10.1080/00049189993648	49	0	0	2	2	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0261-5177	1879-3193		TOURISM MANAGE	Tourism Manage.	APR	2018	65						267	278		10.1016/j.tourman.2017.09.010				12	Environmental Studies; Hospitality, Leisure, Sport & Tourism; Management	Environmental Sciences & Ecology; Social Sciences - Other Topics; Business & Economics	FR3NE	WOS:000418972600024					2018-01-30	
J	Zia, MS; Hussain, M; Jaffar, MA				Zia, M. Sultan; Hussain, Majid; Jaffar, M. Arfan			Incremental Learning-Based Facial Expression Classification System Using a Novel Multinomial Classifier	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Histogram template matching; facial expressions; incremental learning; LBP; machine learning	CULTURAL-DIFFERENCES; IMAGE SEQUENCES; RECOGNITION; EMOTION; FUSION	Facial expressions recognition is a crucial task in pattern recognition and it becomes even crucial when cross-cultural emotions are encountered. Various studies in the past have shown that all the facial expressions are not innate and universal, but many of them are learned and culture-dependent. Extreme facial expression recognition methods employ different datasets for training and later use it for testing and demostrate high accuracy in recognition. Their performances degrade drastically when expression images are taken from different cultures. Moreover, there are many existing facial expression patterns which cannot be generated and used as training data in single training session. A facial expression recognition system can maintain its high accuracy and robustness globally and for a longer period if the system possesses the ability to learn incrementally. We also propose a novel classification algorithm for multinomial classification problems. It is an efficient classifier and can be a good choice for base classifier in real-time applications. We propose a facial expression recognition system that can learn incrementally. We use Local Binary Pattern (LBP) features to represent the expression space. The performance of the system is tested on static images from six different databases containing expressions from various cultures. The experiments using the incremental learning classification demonstrate promising results.	[Zia, M. Sultan; Hussain, Majid] Inst Informat Technol, COMSATS, Sahiwal, Pakistan; [Hussain, Majid; Jaffar, M. Arfan] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia	Hussain, M (reprint author), Inst Informat Technol, COMSATS, Sahiwal, Pakistan.; Hussain, M (reprint author), Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia.	ziactn@ciitsahiwal.edu.pk; majidhussain@ciitsahiwal.edu.pk; majaffar@imamu.edu.sa					Ahn JK, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/340717; Aifanti N., 2010, 2010 11 INT WORKSH I; Birdwhistell R. L., 2011, KINESICS CONTEXT ESS; Braathen B., 2002, P 5 IEEE INT C AUT F; Chen J., 2012, P 4 INT C INT MULT C; Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019; Danelakis A., 2014, MULTIMED TOOLS APPL, V74, P1; Darwin C., 1872, EXPRESSION EMOTIONS; Ekman P., 1978, FACIAL ACTION CODING; Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203; Fang TH, 2012, IMAGE VISION COMPUT, V30, P738, DOI 10.1016/j.imavis.2012.02.004; Guo GD, 2005, IEEE T SYST MAN CY B, V35, P477, DOI 10.1109/TSMCB.2005.846658; Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334; Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750; Izard C. E., 1971, FACE OF EMOTION; Jack RE, 2012, J EXP PSYCHOL GEN, V141, P19, DOI 10.1037/a0023463; Kanade T., 2000, P 4 IEEE INT C AUT F; Klineberg O, 1938, J ABNORM SOC PSYCH, V33, P517, DOI 10.1037/h0057105; Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954; Lucey P., 2010, 2010 IEEE COMP SOC C; Lyons M., 1998, 1998 P 3 IEEE INT C; Marsh AA, 2003, PSYCHOL SCI, V14, P373, DOI 10.1111/1467-9280.24461; MATSUMOTO D, 1989, J CROSS CULT PSYCHOL, V20, P92, DOI 10.1177/0022022189201006; Matsumoto D, 2002, PSYCHOL BULL, V128, P236, DOI 10.1037//0033-2909.128.2.236; MATSUMOTO D, 1992, J NONVERBAL BEHAV, V16, P85, DOI 10.1007/BF00990324; Muhlbaier M. D., 2009, NEURAL NETWORKS IEEE, V20, P152, DOI DOI 10.1109/TNN.2008.2008326; Nan Z., 2006, 2006 8 INT C SIGN PR; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933; Polikar R, 2007, IEEE SIGNAL PROC MAG, V24, P59, DOI 10.1109/MSP.2007.4286565; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Song K. T., 2010, INTEL SERV ROBOT, V3, P151; Tsai JL, 2003, J CROSS CULT PSYCHOL, V34, P650, DOI 10.1177/0022022103256846; Tsai P., 2005, 2005 IEEE INT C SYST; Valstar M., 2015, P 11 IEEE C FAC GEST; Valstar M., 2010, WORKSH P INT C LANG; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710; Xu X., 2015, 2015 IEEE INT C MECH; Yan H, 2012, IET BIOMETRICS, V1, P160, DOI 10.1049/iet-bmt.2012.0006; Yan H., 2011, 2011 IEEE INT C TOB; Zavaschi THH, 2013, EXPERT SYST APPL, V40, P646, DOI 10.1016/j.eswa.2012.07.074; Zhang D., 2015, T ENG TECHNOLOGIES, P413; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; Zhao XM, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-20; Zia M. S., 2015, APPL MATH INFORM SCI, V9, P2651	48	0	0	4	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014	1793-6381		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	APR	2018	32	4							1856004	10.1142/S0218001418560049				26	Computer Science, Artificial Intelligence	Computer Science	FQ0FC	WOS:000418028300012					2018-01-30	
